<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 900px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 900px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Transformer Architecture", "label": "Transformer Architecture", "shape": "dot", "title": "Architecture"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BLEU", "label": "BLEU", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-German translation task", "label": "WMT 2014 English-to-German translation task", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-French translation task", "label": "WMT 2014 English-to-French translation task", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English constituency parsing", "label": "English constituency parsing", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "RNNs", "label": "RNNs", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "self-attention", "label": "self-attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "scaled dot-product attention", "label": "scaled dot-product attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "multi-head attention", "label": "multi-head attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "parameter-free position representation", "label": "parameter-free position representation", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "tensor2tensor", "label": "tensor2tensor", "shape": "dot", "title": "System"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "NIPS 2017", "label": "NIPS 2017", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "arXiv:1706.03762v7", "label": "arXiv:1706.03762v7", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Google Brain", "label": "Google Brain", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Google Research", "label": "Google Research", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Long Beach", "label": "Long Beach", "shape": "dot", "title": "Location"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Jakob", "label": "Jakob", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Ashish", "label": "Ashish", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Illia", "label": "Illia", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Noam", "label": "Noam", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Niki", "label": "Niki", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Llion", "label": "Llion", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Lukasz", "label": "Lukasz", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Aidan", "label": "Aidan", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 2", "label": "Table 2", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3", "label": "Table 3", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Pdrop", "label": "Pdrop", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "beam search", "label": "beam search", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "beam size", "label": "beam size", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "input length", "label": "input length", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "output length", "label": "output length", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "floating point operations", "label": "floating point operations", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "single-precision floating-point capacity", "label": "single-precision floating-point capacity", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "GPU", "label": "GPU", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ensemble", "label": "ensemble", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "state-of-the-art", "label": "state-of-the-art", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "base model", "label": "base model", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "big model", "label": "big model", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "development set", "label": "development set", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ByteNet", "label": "ByteNet", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Deep-Att + PosUnk", "label": "Deep-Att + PosUnk", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "GNMT + RL", "label": "GNMT + RL", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ConvS2S", "label": "ConvS2S", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "MoE", "label": "MoE", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Residual Dropout", "label": "Residual Dropout", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Label Smoothing", "label": "Label Smoothing", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "\u03b5ls", "label": "\u03b5ls", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "newstest2014", "label": "newstest2014", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English-to-German", "label": "English-to-German", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English-to-French", "label": "English-to-French", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Training Cost", "label": "Training Cost", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "FLOPs", "label": "FLOPs", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Perplexity", "label": "Perplexity", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Neural Networks", "label": "Recurrent Neural Networks", "shape": "dot", "title": "Architecture"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Long Short-Term Memory", "label": "Long Short-Term Memory", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Gated Recurrent Neural Networks", "label": "Gated Recurrent Neural Networks", "shape": "dot", "title": "Architecture"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sequence Modeling", "label": "Sequence Modeling", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Language Modeling", "label": "Language Modeling", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Machine Translation", "label": "Machine Translation", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Encoder-Decoder Architectures", "label": "Encoder-Decoder Architectures", "shape": "dot", "title": "Architecture"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Hidden States", "label": "Hidden States", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Attention Mechanisms", "label": "Attention Mechanisms", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Parallelization", "label": "Parallelization", "shape": "dot", "title": "Process"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Computational Efficiency", "label": "Computational Efficiency", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Model Performance", "label": "Model Performance", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sequential Computation", "label": "Sequential Computation", "shape": "dot", "title": "Process"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Factorization Tricks", "label": "Factorization Tricks", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Conditional Computation", "label": "Conditional Computation", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Global Dependencies", "label": "Global Dependencies", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Translation Quality", "label": "Translation Quality", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "P100 GPUs", "label": "P100 GPUs", "shape": "dot", "title": "System"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BERT", "label": "BERT", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "positional encodings", "label": "positional encodings", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "encoder", "label": "encoder", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "decoder", "label": "decoder", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sine", "label": "sine", "shape": "dot", "title": "Function"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "cosine", "label": "cosine", "shape": "dot", "title": "Function"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dimension", "label": "dimension", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dmodel", "label": "dmodel", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "position", "label": "position", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "frequency", "label": "frequency", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "geometric progression", "label": "geometric progression", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sinusoid", "label": "sinusoid", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "row (E)", "label": "row (E)", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence length", "label": "sequence length", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "training", "label": "training", "shape": "dot", "title": "Process"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Neural Network", "label": "Recurrent Neural Network", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Wall Street Journal", "label": "Wall Street Journal", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Penn Treebank", "label": "Penn Treebank", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BerkleyParser", "label": "BerkleyParser", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dropout", "label": "dropout", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention", "label": "attention", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "residual", "label": "residual", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learning rate", "label": "learning rate", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Section 22 development set", "label": "Section 22 development set", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English-to-German base translation model", "label": "English-to-German base translation model", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WSJ", "label": "WSJ", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Neural Network Grammar", "label": "Recurrent Neural Network Grammar", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Neural Network sequence-to-sequence models", "label": "Recurrent Neural Network sequence-to-sequence models", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BerkeleyParser", "label": "BerkeleyParser", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Vinyals \u0026 Kaiser el al.", "label": "Vinyals \u0026 Kaiser el al.", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Petrov et al.", "label": "Petrov et al.", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Zhu et al.", "label": "Zhu et al.", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Dyer et al.", "label": "Dyer et al.", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Huang \u0026 Harper", "label": "Huang \u0026 Harper", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "McClosky et al.", "label": "McClosky et al.", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Luong et al.", "label": "Luong et al.", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 4", "label": "Table 4", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Section 23", "label": "Section 23", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Parser Training", "label": "Parser Training", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "F1", "label": "F1", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-German", "label": "WMT 2014 English-to-German", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-French", "label": "WMT 2014 English-to-French", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "TensorFlow", "label": "TensorFlow", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Nal Kalchbrenner", "label": "Nal Kalchbrenner", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Stephan Gouws", "label": "Stephan Gouws", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Point-Wise Fully Connected Layers", "label": "Point-Wise Fully Connected Layers", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "encoder-decoder attention", "label": "encoder-decoder attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence-to-sequence models", "label": "sequence-to-sequence models", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "softmax", "label": "softmax", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "auto-regressive property", "label": "auto-regressive property", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Extended Neural GPU", "label": "Extended Neural GPU", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "End-to-end memory networks", "label": "End-to-end memory networks", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent attention mechanism", "label": "Recurrent attention mechanism", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sequence-aligned RNNs", "label": "Sequence-aligned RNNs", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Convolutional neural networks", "label": "Convolutional neural networks", "shape": "dot", "title": "Architecture"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Reading comprehension", "label": "Reading comprehension", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Abstractive summarization", "label": "Abstractive summarization", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Textual entailment", "label": "Textual entailment", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Learning task-independent sentence representations", "label": "Learning task-independent sentence representations", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Simple-language question answering", "label": "Simple-language question answering", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "LayerNorm", "label": "LayerNorm", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Positionwise Fully Connected Feed-Forward Network", "label": "Positionwise Fully Connected Feed-Forward Network", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Residual Connection", "label": "Residual Connection", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sublayer", "label": "Sublayer", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Embedding Layers", "label": "Embedding Layers", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Self-Attention Sub-layer", "label": "Self-Attention Sub-layer", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Layer Normalization", "label": "Layer Normalization", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Masking", "label": "Masking", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "FFN", "label": "FFN", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ReLU", "label": "ReLU", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dff", "label": "dff", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "max", "label": "max", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "W1", "label": "W1", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "b1", "label": "b1", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "W2", "label": "W2", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "b2", "label": "b2", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "convolution", "label": "convolution", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "kernel size", "label": "kernel size", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "activation", "label": "activation", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "layer", "label": "layer", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "checkpoint averaging", "label": "checkpoint averaging", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention heads", "label": "attention heads", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention key and value dimensions", "label": "attention key and value dimensions", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dot product", "label": "dot product", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learned positional embeddings", "label": "learned positional embeddings", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sinusoidal positional encoding", "label": "sinusoidal positional encoding", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Section 3.2.2", "label": "Section 3.2.2", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "newstest2013", "label": "newstest2013", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dkhurts model", "label": "dkhurts model", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3 rows (A)", "label": "Table 3 rows (A)", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3 rows (B)", "label": "Table 3 rows (B)", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3 rows (C)", "label": "Table 3 rows (C)", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3 rows (D)", "label": "Table 3 rows (D)", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3 rows (E)", "label": "Table 3 rows (E)", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Query", "label": "Query", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Key", "label": "Key", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Value", "label": "Value", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Additive Attention", "label": "Additive Attention", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Dot-Product Attention", "label": "Dot-Product Attention", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Feed-Forward Network", "label": "Feed-Forward Network", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Matrix Multiplication", "label": "Matrix Multiplication", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Matrix Q", "label": "Matrix Q", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Matrix K", "label": "Matrix K", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Matrix V", "label": "Matrix V", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dk", "label": "dk", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dv", "label": "dv", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Matrix Multiplication Code", "label": "Matrix Multiplication Code", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "NVIDIA P100", "label": "NVIDIA P100", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "CIFAR-10", "label": "CIFAR-10", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "LoRA", "label": "LoRA", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Hyperparameter", "label": "Hyperparameter", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Model", "label": "Model", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Step", "label": "Step", "shape": "dot", "title": "Process"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Machine", "label": "Machine", "shape": "dot", "title": "System"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Hours", "label": "Hours", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Days", "label": "Days", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Seconds", "label": "Seconds", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English-to-German translation", "label": "English-to-German translation", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "TFLOPS", "label": "TFLOPS", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "K80", "label": "K80", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "K40", "label": "K40", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "M40", "label": "M40", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "P100", "label": "P100", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WO", "label": "WO", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WQ", "label": "WQ", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WK", "label": "WK", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WV", "label": "WV", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "head i", "label": "head i", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "head 1, ...,head h", "label": "head 1, ...,head h", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Concat", "label": "Concat", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Single-head attention", "label": "Single-head attention", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "softmax function", "label": "softmax function", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "weight matrix", "label": "weight matrix", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "linear transformation", "label": "linear transformation", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "next-token probabilities", "label": "next-token probabilities", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "predicted next-token probabilities", "label": "predicted next-token probabilities", "shape": "dot", "title": "Result"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "input tokens", "label": "input tokens", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "output tokens", "label": "output tokens", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dimension dmodel", "label": "dimension dmodel", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "pre-softmax linear transformation", "label": "pre-softmax linear transformation", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learned embeddings", "label": "learned embeddings", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learned linear transformation", "label": "learned linear transformation", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence transduction models", "label": "sequence transduction models", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "tokens", "label": "tokens", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "vectors", "label": "vectors", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Adam", "label": "Adam", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "\u03b21", "label": "\u03b21", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "\u03b22", "label": "\u03b22", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "step_num", "label": "step_num", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "warmup _steps", "label": "warmup _steps", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "lrate", "label": "lrate", "shape": "dot", "title": "Formula"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "step _num", "label": "step _num", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Key-Value Pairs", "label": "Key-Value Pairs", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Output", "label": "Output", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Vector", "label": "Vector", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Weighted Sum", "label": "Weighted Sum", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Compatibility function", "label": "Compatibility function", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "28.4 BLEU", "label": "28.4 BLEU", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "41.8 BLEU", "label": "41.8 BLEU", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "novel model variants", "label": "novel model variants", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "high-confidence", "label": "high-confidence", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "16K tokens", "label": "16K tokens", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "32K tokens", "label": "32K tokens", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "multi-headed self-attention", "label": "multi-headed self-attention", "shape": "dot", "title": "Mechanism"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "problems involving input and output modalities other than text", "label": "problems involving input and output modalities other than text", "shape": "dot", "title": "Domain"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "new state of the art", "label": "new state of the art", "shape": "dot", "title": "Achievement"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "training speed", "label": "training speed", "shape": "dot", "title": "Attribute"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention-based models", "label": "attention-based models", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Nal Kalchbrenner and Stephan Gouws", "label": "Nal Kalchbrenner and Stephan Gouws", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Variations on the Transformer Architecture", "label": "Variations on the Transformer Architecture", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "metrics", "label": "metrics", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "perplexities", "label": "perplexities", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "per-wordpiece", "label": "per-wordpiece", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "per-word", "label": "per-word", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "steps", "label": "steps", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "params", "label": "params", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "PPL", "label": "PPL", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Effective resolution", "label": "Effective resolution", "shape": "dot", "title": "Property"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "encoder-decoder structure", "label": "encoder-decoder structure", "shape": "dot", "title": "structure"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence of continuous representations z= (z1, ..., z n)", "label": "sequence of continuous representations z= (z1, ..., z n)", "shape": "dot", "title": "representation"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "output sequence (y1, ..., y m)of symbols", "label": "output sequence (y1, ..., y m)of symbols", "shape": "dot", "title": "output"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "auto-regressive", "label": "auto-regressive", "shape": "dot", "title": "property"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "self-attention layers", "label": "self-attention layers", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "recurrent and convolutional layers", "label": "recurrent and convolutional layers", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence transduction encoder or decoder", "label": "sequence transduction encoder or decoder", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "constant number of sequentially executed operations", "label": "constant number of sequentially executed operations", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "recurrent layers", "label": "recurrent layers", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "O(n)sequential operations", "label": "O(n)sequential operations", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ability to learn long-range dependencies", "label": "ability to learn long-range dependencies", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "path length", "label": "path length", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence transduction tasks", "label": "sequence transduction tasks", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "convolutional layers", "label": "convolutional layers", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sentence representations", "label": "sentence representations", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "computational performance", "label": "computational performance", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "increased maximum path length", "label": "increased maximum path length", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "neighborhood size r", "label": "neighborhood size r", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "input and output positions", "label": "input and output positions", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "increased length of longest paths", "label": "increased length of longest paths", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "kernel width k", "label": "kernel width k", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "separable convolutions", "label": "separable convolutions", "shape": "dot", "title": "method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "complexity", "label": "complexity", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "O(k\u00b7n\u00b7d+n\u00b7d2) complexity", "label": "O(k\u00b7n\u00b7d+n\u00b7d2) complexity", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "separable convolution", "label": "separable convolution", "shape": "dot", "title": "method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "point-wise feed-forward layer", "label": "point-wise feed-forward layer", "shape": "dot", "title": "method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "interpretable models", "label": "interpretable models", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention distributions", "label": "attention distributions", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "syntactic and semantic structure", "label": "syntactic and semantic structure", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "2.8 TFLOPS", "label": "2.8 TFLOPS", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "3.7 TFLOPS", "label": "3.7 TFLOPS", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "6.0 TFLOPS", "label": "6.0 TFLOPS", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "9.5 TFLOPS", "label": "9.5 TFLOPS", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "queries, keys and values", "label": "queries, keys and values", "shape": "dot", "title": "entities"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "different, learned linear projections", "label": "different, learned linear projections", "shape": "dot", "title": "entities"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "the attention function", "label": "the attention function", "shape": "dot", "title": "entities"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dot products", "label": "dot products", "shape": "dot", "title": "entities"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "the components of q and k", "label": "the components of q and k", "shape": "dot", "title": "entities"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "independent random variables with mean 0 and variance 1", "label": "independent random variables with mean 0 and variance 1", "shape": "dot", "title": "entities"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel", "label": "we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel", "shape": "dot", "title": "Method"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "decoder output", "label": "decoder output", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "\u221admodel", "label": "\u221admodel", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Figure 2", "label": "Figure 2", "shape": "dot", "title": "Figure"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention layers", "label": "attention layers", "shape": "dot", "title": "Concept"}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "scaled dot-product attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "multi-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "parameter-free position representation"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "tensor2tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "28.4 BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "41.8 BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "APPLIED_TO", "to": "English constituency parsing"}, {"arrows": "to", "color": "#97c2fc", "from": "Jakob", "label": "PROPOSED", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Ashish", "label": "DESIGNED", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Noam", "label": "PROPOSED", "to": "scaled dot-product attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Niki", "label": "DESIGNED", "to": "tensor2tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Llion", "label": "EXPERIMENTED_WITH", "to": "novel model variants"}, {"arrows": "to", "color": "#97c2fc", "from": "Lukasz", "label": "DESIGNED", "to": "tensor2tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Aidan", "label": "DESIGNED", "to": "tensor2tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Google Brain", "label": "BASED_AT", "to": "Long Beach"}, {"arrows": "to", "color": "#97c2fc", "from": "Google Research", "label": "BASED_AT", "to": "Long Beach"}, {"arrows": "to", "color": "#97c2fc", "from": "NIPS 2017", "label": "HOSTED", "to": "Long Beach"}, {"arrows": "to", "color": "#97c2fc", "from": "arXiv:1706.03762v7", "label": "PUBLISHED_IN", "to": "NIPS 2017"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "Training Cost"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "PART_OF", "to": "Residual Dropout"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "PART_OF", "to": "Label Smoothing"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "Pdrop"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "\u03b5ls"}, {"arrows": "to", "color": "#97c2fc", "from": "BLEU", "label": "IMPROVES", "to": "Label Smoothing"}, {"arrows": "to", "color": "#97c2fc", "from": "Training Cost", "label": "DEPENDS_ON", "to": "FLOPs"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "RELATED_TO", "to": "Long Short-Term Memory"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "RELATED_TO", "to": "Gated Recurrent Neural Networks"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "RELATED_TO", "to": "Encoder-Decoder Architectures"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Long Short-Term Memory", "label": "RELATED_TO", "to": "Gated Recurrent Neural Networks"}, {"arrows": "to", "color": "#97c2fc", "from": "Gated Recurrent Neural Networks", "label": "RELATED_TO", "to": "Encoder-Decoder Architectures"}, {"arrows": "to", "color": "#97c2fc", "from": "Encoder-Decoder Architectures", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Encoder-Decoder Architectures", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Encoder-Decoder Architectures", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Sequence Modeling", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Sequence Modeling", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Language Modeling", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "USES", "to": "Hidden States"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "USES", "to": "Attention Mechanisms"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "LIMITS", "to": "Parallelization"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "LIMITS", "to": "Computational Efficiency"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Networks", "label": "IMPROVES", "to": "Model Performance"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Attention Mechanisms"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "Translation Quality"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encodings", "label": "CONTAINS", "to": "sine"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encodings", "label": "CONTAINS", "to": "cosine"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encodings", "label": "CONTAINS", "to": "dimension"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "CONTAINS", "to": "positional encodings"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "CONTAINS", "to": "positional encodings"}, {"arrows": "to", "color": "#97c2fc", "from": "sine", "label": "USED_IN", "to": "positional encodings"}, {"arrows": "to", "color": "#97c2fc", "from": "cosine", "label": "USED_IN", "to": "positional encodings"}, {"arrows": "to", "color": "#97c2fc", "from": "dimension", "label": "EQUAL_TO", "to": "dmodel"}, {"arrows": "to", "color": "#97c2fc", "from": "dimension", "label": "DEFINED_AS", "to": "geometric progression"}, {"arrows": "to", "color": "#97c2fc", "from": "position", "label": "DEFINED_AS", "to": "sinusoid"}, {"arrows": "to", "color": "#97c2fc", "from": "frequency", "label": "DEFINED_AS", "to": "geometric progression"}, {"arrows": "to", "color": "#97c2fc", "from": "geometric progression", "label": "DEFINED_AS", "to": "sequence length"}, {"arrows": "to", "color": "#97c2fc", "from": "sequence length", "label": "RELATED_TO", "to": "training"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "RESULTS_IN", "to": "row (E)"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USED_TO_PERFORM_EXPERIMENTS_ON", "to": "English constituency parsing"}, {"arrows": "to", "color": "#97c2fc", "from": "English constituency parsing", "label": "PRESENTS_SPECIFIC_CHALLENGES", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "FAILED_TO_ATTAIN_STATE_OF_THE_ART_RESULTS", "to": "English constituency parsing"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "TRAINED_ON", "to": "Wall Street Journal"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "TRAINED_ON", "to": "Penn Treebank"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USED_IN_SEMI_SUPERVISED_SETTING", "to": "BerkleyParser"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USED_IN_SEMI_SUPERVISED_SETTING", "to": "high-confidence"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USED_VOCABULARY", "to": "16K tokens"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USED_VOCABULARY", "to": "32K tokens"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "SELECTED_HYPERPARAMETERS", "to": "dropout"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "SELECTED_HYPERPARAMETERS", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "SELECTED_HYPERPARAMETERS", "to": "residual"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "SELECTED_HYPERPARAMETERS", "to": "learning rate"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "SELECTED_HYPERPARAMETERS", "to": "beam size"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USED_PARAMETERS_FROM", "to": "English-to-German base translation model"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "multi-headed self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "problems involving input and output modalities other than text"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "new state of the art"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPROVES", "to": "training speed"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "attention-based models"}, {"arrows": "to", "color": "#97c2fc", "from": "TensorFlow", "label": "CITES", "to": "Nal Kalchbrenner and Stephan Gouws"}, {"arrows": "to", "color": "#97c2fc", "from": "tensor2tensor", "label": "IMPLEMENTS", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Nal Kalchbrenner", "label": "CITED_BY", "to": "TensorFlow"}, {"arrows": "to", "color": "#97c2fc", "from": "Stephan Gouws", "label": "CITED_BY", "to": "TensorFlow"}, {"arrows": "to", "color": "#97c2fc", "from": "WMT 2014 English-to-German", "label": "RELATED_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "WMT 2014 English-to-French", "label": "RELATED_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "encoder"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "decoder"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "Point-Wise Fully Connected Layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "multi-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "encoder-decoder attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "scaled dot-product attention"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder-decoder attention", "label": "PART_OF", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "PART_OF", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "scaled dot-product attention", "label": "PART_OF", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "multi-head attention", "label": "USED_BY", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder-decoder attention", "label": "USED_BY", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_BY", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "scaled dot-product attention", "label": "USED_BY", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "sequence-to-sequence models", "label": "COMPARED_TO", "to": "encoder-decoder attention"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "CONTAINS", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "CONTAINS", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_BY", "to": "encoder"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_BY", "to": "decoder"}, {"arrows": "to", "color": "#97c2fc", "from": "auto-regressive property", "label": "LIMITS", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Variations on the Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "base model", "label": "RELATED_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "metrics", "label": "EVALUATES", "to": "perplexities"}, {"arrows": "to", "color": "#97c2fc", "from": "perplexities", "label": "CONTAINS", "to": "per-wordpiece"}, {"arrows": "to", "color": "#97c2fc", "from": "perplexities", "label": "CONTAINS", "to": "per-word"}, {"arrows": "to", "color": "#97c2fc", "from": "newstest2013", "label": "USED_IN", "to": "metrics"}, {"arrows": "to", "color": "#97c2fc", "from": "base model", "label": "TRAINED_ON", "to": "newstest2013"}, {"arrows": "to", "color": "#97c2fc", "from": "steps", "label": "RESULTS_IN", "to": "perplexities"}, {"arrows": "to", "color": "#97c2fc", "from": "steps", "label": "RESULTS_IN", "to": "BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "steps", "label": "RESULTS_IN", "to": "params"}, {"arrows": "to", "color": "#97c2fc", "from": "PPL", "label": "RESULTS_IN", "to": "BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "PPL", "label": "RESULTS_IN", "to": "params"}, {"arrows": "to", "color": "#97c2fc", "from": "BLEU", "label": "RESULTS_IN", "to": "params"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "IMPLEMENTS", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "ACHIEVES", "to": "perplexities"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "ACHIEVES", "to": "BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "ACHIEVES", "to": "params"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "DEPENDS_ON", "to": "steps"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "DEPENDS_ON", "to": "PPL"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "DEPENDS_ON", "to": "BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "DEPENDS_ON", "to": "params"}, {"arrows": "to", "color": "#97c2fc", "from": "Extended Neural GPU", "label": "USES", "to": "Convolutional neural networks"}, {"arrows": "to", "color": "#97c2fc", "from": "ByteNet", "label": "USES", "to": "Convolutional neural networks"}, {"arrows": "to", "color": "#97c2fc", "from": "ConvS2S", "label": "USES", "to": "Convolutional neural networks"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPROVES", "to": "Effective resolution"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_IN", "to": "Reading comprehension"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_IN", "to": "Abstractive summarization"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_IN", "to": "Textual entailment"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USED_IN", "to": "Learning task-independent sentence representations"}, {"arrows": "to", "color": "#97c2fc", "from": "End-to-end memory networks", "label": "USED_IN", "to": "Simple-language question answering"}, {"arrows": "to", "color": "#97c2fc", "from": "End-to-end memory networks", "label": "USED_IN", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "COMPARED_TO", "to": "Sequence-aligned RNNs"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "CONTAINS", "to": "LayerNorm"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "CONTAINS", "to": "Sublayer"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "CONTAINS", "to": "Embedding Layers"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "USES", "to": "Residual Connection"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "USES", "to": "LayerNorm"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "USES", "to": "multi-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "USES", "to": "Positionwise Fully Connected Feed-Forward Network"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "USES", "to": "dmodel"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "CONTAINS", "to": "LayerNorm"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "CONTAINS", "to": "Sublayer"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "CONTAINS", "to": "Embedding Layers"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "USES", "to": "Residual Connection"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "USES", "to": "LayerNorm"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "USES", "to": "multi-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "USES", "to": "Positionwise Fully Connected Feed-Forward Network"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "USES", "to": "dmodel"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "USES", "to": "Masking"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "PART_OF", "to": "Model"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "PART_OF", "to": "Model"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "CONTAINS", "to": "ReLU"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "CONTAINS", "to": "layer"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "CONTAINS", "to": "position"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "USES", "to": "W1"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "USES", "to": "b1"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "USES", "to": "W2"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "USES", "to": "b2"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "PART_OF", "to": "encoder"}, {"arrows": "to", "color": "#97c2fc", "from": "FFN", "label": "PART_OF", "to": "decoder"}, {"arrows": "to", "color": "#97c2fc", "from": "ReLU", "label": "USED_IN", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "layer", "label": "CONTAINS", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "position", "label": "CONTAINS", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "W1", "label": "USED_IN", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "b1", "label": "USED_IN", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "W2", "label": "USED_IN", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "b2", "label": "USED_IN", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "convolution", "label": "EQUIVALENT_TO", "to": "FFN"}, {"arrows": "to", "color": "#97c2fc", "from": "beam search", "label": "USES", "to": "newstest2013"}, {"arrows": "to", "color": "#97c2fc", "from": "beam search", "label": "USES", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "checkpoint averaging", "label": "NOT_USED", "to": "newstest2013"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "CONTAINS", "to": "Table 3 rows (A)"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "CONTAINS", "to": "Table 3 rows (B)"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "CONTAINS", "to": "Table 3 rows (C)"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "CONTAINS", "to": "Table 3 rows (D)"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "CONTAINS", "to": "Table 3 rows (E)"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3 rows (A)", "label": "PART_OF", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3 rows (B)", "label": "PART_OF", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3 rows (C)", "label": "PART_OF", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3 rows (D)", "label": "PART_OF", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3 rows (E)", "label": "PART_OF", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "attention heads", "label": "VARY", "to": "Table 3 rows (A)"}, {"arrows": "to", "color": "#97c2fc", "from": "attention key and value dimensions", "label": "VARY", "to": "Table 3 rows (A)"}, {"arrows": "to", "color": "#97c2fc", "from": "dkhurts model", "label": "USED", "to": "Table 3 rows (B)"}, {"arrows": "to", "color": "#97c2fc", "from": "dot product", "label": "MAY_BE_BENEFICIAL", "to": "Table 3 rows (B)"}, {"arrows": "to", "color": "#97c2fc", "from": "dropout", "label": "HELPFUL", "to": "Table 3 rows (C)"}, {"arrows": "to", "color": "#97c2fc", "from": "dropout", "label": "HELPFUL", "to": "Table 3 rows (D)"}, {"arrows": "to", "color": "#97c2fc", "from": "learned positional embeddings", "label": "USED", "to": "Table 3 rows (E)"}, {"arrows": "to", "color": "#97c2fc", "from": "sinusoidal positional encoding", "label": "REPLACED", "to": "Table 3 rows (E)"}, {"arrows": "to", "color": "#97c2fc", "from": "base model", "label": "USED_AS_REFERENCE", "to": "Table 3 rows (E)"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder-decoder structure", "label": "CONTAINS", "to": "encoder"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder-decoder structure", "label": "CONTAINS", "to": "decoder"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder", "label": "MAPS_TO", "to": "sequence of continuous representations z= (z1, ..., z n)"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "GENERATES", "to": "output sequence (y1, ..., y m)of symbols"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "IS_AUTO_REGRESSIVE", "to": "auto-regressive"}, {"arrows": "to", "color": "#97c2fc", "from": "scaled dot-product attention", "label": "RELATED_TO", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "attention", "label": "USES", "to": "softmax"}, {"arrows": "to", "color": "#97c2fc", "from": "attention", "label": "USES", "to": "Matrix Multiplication"}, {"arrows": "to", "color": "#97c2fc", "from": "attention", "label": "USES", "to": "Matrix Multiplication Code"}, {"arrows": "to", "color": "#97c2fc", "from": "Additive Attention", "label": "RELATED_TO", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Dot-Product Attention", "label": "RELATED_TO", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Dot-Product Attention", "label": "USES", "to": "Matrix Multiplication"}, {"arrows": "to", "color": "#97c2fc", "from": "Dot-Product Attention", "label": "USES", "to": "Matrix Multiplication Code"}, {"arrows": "to", "color": "#97c2fc", "from": "Additive Attention", "label": "USES", "to": "Feed-Forward Network"}, {"arrows": "to", "color": "#97c2fc", "from": "Additive Attention", "label": "USES", "to": "Matrix Multiplication"}, {"arrows": "to", "color": "#97c2fc", "from": "Additive Attention", "label": "USES", "to": "Matrix Multiplication Code"}, {"arrows": "to", "color": "#97c2fc", "from": "Additive Attention", "label": "OUTPERFORMS", "to": "Dot-Product Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Dot-Product Attention", "label": "OUTPERFORMED_BY", "to": "Additive Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "softmax", "label": "USED_BY", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Matrix Multiplication", "label": "USED_BY", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Matrix Multiplication Code", "label": "USED_BY", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Feed-Forward Network", "label": "USED_BY", "to": "Additive Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "dk", "label": "USED_IN", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "dv", "label": "USED_IN", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Matrix Q", "label": "USED_IN", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Matrix K", "label": "USED_IN", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Matrix V", "label": "USED_IN", "to": "attention"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "RELATED_TO", "to": "recurrent and convolutional layers"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "RELATED_TO", "to": "sequence transduction encoder or decoder"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "USES", "to": "constant number of sequentially executed operations"}, {"arrows": "to", "color": "#97c2fc", "from": "recurrent layers", "label": "USES", "to": "O(n)sequential operations"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "IMPROVES", "to": "ability to learn long-range dependencies"}, {"arrows": "to", "color": "#97c2fc", "from": "path length", "label": "AFFECTS", "to": "ability to learn long-range dependencies"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "RELATED_TO", "to": "sequence transduction tasks"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "COMPARABLE_TO", "to": "recurrent layers"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "COMPARABLE_TO", "to": "convolutional layers"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "USES", "to": "sentence representations"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "IMPROVES", "to": "computational performance"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "RESULTS_IN", "to": "increased maximum path length"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "DEPENDS_ON", "to": "neighborhood size r"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layers", "label": "USES", "to": "input and output positions"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layers", "label": "RESULTS_IN", "to": "increased length of longest paths"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layers", "label": "DEPENDS_ON", "to": "kernel width k"}, {"arrows": "to", "color": "#97c2fc", "from": "separable convolutions", "label": "DECREASES", "to": "complexity"}, {"arrows": "to", "color": "#97c2fc", "from": "separable convolutions", "label": "RESULTS_IN", "to": "O(k\u00b7n\u00b7d+n\u00b7d2) complexity"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "COMPARABLE_TO", "to": "separable convolution"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "COMPARABLE_TO", "to": "point-wise feed-forward layer"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention", "label": "ILLUSTRATES", "to": "interpretable models"}, {"arrows": "to", "color": "#97c2fc", "from": "attention distributions", "label": "ILLUSTRATES", "to": "syntactic and semantic structure"}, {"arrows": "to", "color": "#97c2fc", "from": "NVIDIA P100", "label": "USES", "to": "GPU"}, {"arrows": "to", "color": "#97c2fc", "from": "GPU", "label": "PART_OF", "to": "Machine"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "TRAINED_ON", "to": "Machine"}, {"arrows": "to", "color": "#97c2fc", "from": "Model", "label": "TRAINED_ON", "to": "NVIDIA P100"}, {"arrows": "to", "color": "#97c2fc", "from": "Step", "label": "PART_OF", "to": "training"}, {"arrows": "to", "color": "#97c2fc", "from": "Step", "label": "RESULTS_IN", "to": "Seconds"}, {"arrows": "to", "color": "#97c2fc", "from": "training", "label": "ACHIEVES", "to": "Seconds"}, {"arrows": "to", "color": "#97c2fc", "from": "Step", "label": "RESULTS_IN", "to": "Days"}, {"arrows": "to", "color": "#97c2fc", "from": "training", "label": "ACHIEVES", "to": "Days"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "DESCRIBED_IN", "to": "Model"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "DESCRIBED_IN", "to": "Step"}, {"arrows": "to", "color": "#97c2fc", "from": "Table 3", "label": "DESCRIBED_IN", "to": "training"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "K80"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "K40"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "M40"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "P100"}, {"arrows": "to", "color": "#97c2fc", "from": "English-to-German translation", "label": "EVALUATES", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "TFLOPS", "label": "USED_TO_MEASURE", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "K80", "label": "USED", "to": "2.8 TFLOPS"}, {"arrows": "to", "color": "#97c2fc", "from": "K40", "label": "USED", "to": "3.7 TFLOPS"}, {"arrows": "to", "color": "#97c2fc", "from": "M40", "label": "USED", "to": "6.0 TFLOPS"}, {"arrows": "to", "color": "#97c2fc", "from": "P100", "label": "USED", "to": "9.5 TFLOPS"}, {"arrows": "to", "color": "#97c2fc", "from": "queries, keys and values", "label": "USES", "to": "different, learned linear projections"}, {"arrows": "to", "color": "#97c2fc", "from": "queries, keys and values", "label": "USES", "to": "the attention function"}, {"arrows": "to", "color": "#97c2fc", "from": "dot products", "label": "DESCRIBED_IN", "to": "the components of q and k"}, {"arrows": "to", "color": "#97c2fc", "from": "dot products", "label": "DESCRIBED_IN", "to": "independent random variables with mean 0 and variance 1"}, {"arrows": "to", "color": "#97c2fc", "from": "sequence transduction models", "label": "RELATED_TO", "to": "we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel"}, {"arrows": "to", "color": "#97c2fc", "from": "learned embeddings", "label": "USES", "to": "input tokens"}, {"arrows": "to", "color": "#97c2fc", "from": "learned embeddings", "label": "USES", "to": "output tokens"}, {"arrows": "to", "color": "#97c2fc", "from": "learned embeddings", "label": "CONVERTS_TO", "to": "vectors"}, {"arrows": "to", "color": "#97c2fc", "from": "learned embeddings", "label": "HAS_DIMENSION", "to": "dimension dmodel"}, {"arrows": "to", "color": "#97c2fc", "from": "learned linear transformation", "label": "USES", "to": "decoder output"}, {"arrows": "to", "color": "#97c2fc", "from": "softmax function", "label": "USES", "to": "decoder output"}, {"arrows": "to", "color": "#97c2fc", "from": "softmax function", "label": "CONVERTS_TO", "to": "predicted next-token probabilities"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder", "label": "OUTPUTS", "to": "decoder output"}, {"arrows": "to", "color": "#97c2fc", "from": "decoder output", "label": "CONVERTS_TO", "to": "predicted next-token probabilities"}, {"arrows": "to", "color": "#97c2fc", "from": "weight matrix", "label": "SHARED_WITH", "to": "Embedding Layers"}, {"arrows": "to", "color": "#97c2fc", "from": "weight matrix", "label": "SHARED_WITH", "to": "pre-softmax linear transformation"}, {"arrows": "to", "color": "#97c2fc", "from": "Embedding Layers", "label": "SHARED_WEIGHTS_WITH", "to": "weight matrix"}, {"arrows": "to", "color": "#97c2fc", "from": "Embedding Layers", "label": "HAS_WEIGHTS", "to": "weight matrix"}, {"arrows": "to", "color": "#97c2fc", "from": "pre-softmax linear transformation", "label": "SHARED_WEIGHTS_WITH", "to": "weight matrix"}, {"arrows": "to", "color": "#97c2fc", "from": "pre-softmax linear transformation", "label": "HAS_WEIGHTS", "to": "weight matrix"}, {"arrows": "to", "color": "#97c2fc", "from": "weight matrix", "label": "IS_MULTIPLIED_BY", "to": "\u221admodel"}, {"arrows": "to", "color": "#97c2fc", "from": "Embedding Layers", "label": "USES", "to": "weight matrix"}, {"arrows": "to", "color": "#97c2fc", "from": "weight matrix", "label": "IS_MULTIPLIED_BY", "to": "dimension dmodel"}, {"arrows": "to", "color": "#97c2fc", "from": "Embedding Layers", "label": "CONVERTS_INPUT_TO", "to": "vectors"}, {"arrows": "to", "color": "#97c2fc", "from": "Adam", "label": "USES", "to": "\u03b21"}, {"arrows": "to", "color": "#97c2fc", "from": "Adam", "label": "USES", "to": "\u03b22"}, {"arrows": "to", "color": "#97c2fc", "from": "Adam", "label": "USES", "to": "learning rate"}, {"arrows": "to", "color": "#97c2fc", "from": "lrate", "label": "DEFINES", "to": "learning rate"}, {"arrows": "to", "color": "#97c2fc", "from": "lrate", "label": "USES", "to": "step_num"}, {"arrows": "to", "color": "#97c2fc", "from": "lrate", "label": "USES", "to": "warmup _steps"}, {"arrows": "to", "color": "#97c2fc", "from": "scaled dot-product attention", "label": "DESCRIBED_IN", "to": "Figure 2"}, {"arrows": "to", "color": "#97c2fc", "from": "multi-head attention", "label": "DESCRIBED_IN", "to": "Figure 2"}, {"arrows": "to", "color": "#97c2fc", "from": "multi-head attention", "label": "CONTAINS", "to": "attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "multi-head attention", "label": "PART_OF", "to": "attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "multi-head attention", "label": "USES", "to": "Compatibility function"}, {"arrows": "to", "color": "#97c2fc", "from": "Compatibility function", "label": "USED_BY", "to": "multi-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Compatibility function", "label": "USED_BY", "to": "scaled dot-product attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Query", "label": "USED_BY", "to": "Compatibility function"}, {"arrows": "to", "color": "#97c2fc", "from": "Key", "label": "USED_BY", "to": "Compatibility function"}, {"arrows": "to", "color": "#97c2fc", "from": "Compatibility function", "label": "USES", "to": "Query"}, {"arrows": "to", "color": "#97c2fc", "from": "Compatibility function", "label": "USES", "to": "Key"}, {"arrows": "to", "color": "#97c2fc", "from": "Query", "label": "CORRESPONDS_TO", "to": "Key"}, {"arrows": "to", "color": "#97c2fc", "from": "Key", "label": "CORRESPONDS_TO", "to": "Key"}, {"arrows": "to", "color": "#97c2fc", "from": "Value", "label": "USED_BY", "to": "Compatibility function"}, {"arrows": "to", "color": "#97c2fc", "from": "Compatibility function", "label": "USES", "to": "Value"}, {"arrows": "to", "color": "#97c2fc", "from": "attention", "label": "RELATED_TO", "to": "multi-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "attention", "label": "RELATED_TO", "to": "scaled dot-product attention"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"physics": {"forceAtlas2Based": {"gravitationalConstant": -50, "centralGravity": 0.01, "springLength": 110, "springConstant": 0.08}, "maxVelocity": 50, "solver": "forceAtlas2Based", "timestep": 0.35, "stabilization": {"enabled": true, "iterations": 900}}, "interaction": {"navigationButtons": true, "keyboard": true, "hover": true, "zoomView": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>